{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4920 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset = keras.utils.image_dataset_from_directory(\n",
    "    \"../celeb_data/data/\",\n",
    "    label_mode=None,\n",
    "    image_size=(64,64),\n",
    "    batch_size=32,\n",
    "    smart_resize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda x: x/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for x in dataset:\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow((x.numpy()*255).astype(\"int32\")[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output layers with one nueron and sigmoid activation because it is a classifier,\n",
    "# that classifies real and fake images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    \"\"\"\n",
    "    Discriminator model for adversarial training.\n",
    "\n",
    "    This function defines a discriminator model that takes an input image of shape (64, 64, 3) and outputs a probability\n",
    "    indicating whether the input image is real or fake.\n",
    "\n",
    "    Returns:\n",
    "        keras.Model: The discriminator model.\n",
    "    \"\"\"\n",
    "    input = keras.Input(shape=(64, 64, 3))\n",
    "    x = layers.Conv2D(64, kernel_size = 4, strides= 2, padding =\"same\")(input)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = layers.Conv2D(128, kernel_size = 4, strides= 2, padding =\"same\")(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = layers.Conv2D(128, kernel_size = 4, strides= 2, padding =\"same\")(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    discriminator_output = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    discriminator = keras.Model(input, discriminator_output)\n",
    "\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 32, 32, 64)        3136      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 128)       131200    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 128)         262272    \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 8193      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 404,801\n",
      "Trainable params: 404,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Output units =3: In color images, each pixel is represented by three values corresponding to the intensities of the red, green, and blue channels (RGB). Therefore, to generate a full-color image, the output layer of the generator needs to produce values for each of these channels.\n",
    "2.  Hence, there are three units in the output layer, each representing one of the RGB channels.\n",
    "\n",
    "3. Sigmoid Activation: The sigmoid activation function is commonly used in the output layer of a generator network for image generation tasks because it scales the output values to the range [0, 1]. In the context of RGB images, this range corresponds to valid pixel intensity values.\n",
    "4. By using the sigmoid activation function, the generator can output pixel values that are within the valid range for each RGB channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    \"\"\"\n",
    "    Generator model for generating synthetic images.\n",
    "\n",
    "    This function defines a generator model that takes a latent vector as input and generates synthetic images\n",
    "    of shape (64, 64, 3).\n",
    "\n",
    "    Returns:\n",
    "        keras.Model: The generator model.\n",
    "    \"\"\"\n",
    "    latent_input = keras.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(8 * 8 * 128)(latent_input)\n",
    "    x = layers.Reshape((8, 8, 128))(x)\n",
    "    x = layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\")(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\")(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\")(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    generator_output = layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\")(x)\n",
    "    generator = keras.Model(latent_input, generator_output)\n",
    "\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 128)]             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8192)              1056768   \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 16, 16, 128)      262272    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 256)      524544    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 64, 64, 512)      2097664   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 64, 64, 512)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 64, 64, 3)         38403     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,979,651\n",
      "Trainable params: 3,979,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = generator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The adversarial network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(keras.Model):\n",
    "    \"\"\"\n",
    "    Generative Adversarial Network (GAN) model.\n",
    "\n",
    "    This class represents a GAN model consisting of a discriminator and a generator.\n",
    "\n",
    "    Args:\n",
    "        discriminator (keras.Model): The discriminator model.\n",
    "        generator (keras.Model): The generator model.\n",
    "        latent_dim (int): The dimensionality of the latent space.\n",
    "\n",
    "    Attributes:\n",
    "        discriminator (keras.Model): The discriminator model.\n",
    "        generator (keras.Model): The generator model.\n",
    "        latent_dim (int): The dimensionality of the latent space.\n",
    "        d_loss_metric (keras.metrics.Mean): Metric to track the discriminator loss during training.\n",
    "        g_loss_metric (keras.metrics.Mean): Metric to track the generator loss during training.\n",
    "    \"\"\"\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        \"\"\"\n",
    "        Initialize the GAN model.\n",
    "\n",
    "        Args:\n",
    "            discriminator (keras.Model): The discriminator model.\n",
    "            generator (keras.Model): The generator model.\n",
    "            latent_dim (int): The dimensionality of the latent space.\n",
    "        \"\"\"\n",
    "        # super is required to initialize the keras.Model in th GAN class.\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        \"\"\"\n",
    "        Configure the GAN model for training.\n",
    "\n",
    "        Args:\n",
    "            d_optimizer: The optimizer for the discriminator.\n",
    "            g_optimizer: The optimizer for the generator.\n",
    "            loss_fn: The loss function to use.\n",
    "        \"\"\"\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        \"\"\"\n",
    "        Return custom metrics to track during training.\n",
    "\n",
    "        Returns:\n",
    "            list: List of metrics to track.\n",
    "        \"\"\"\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "    \n",
    "    def train_step(self, real_images):\n",
    "        \"\"\"\n",
    "        Perform a single training step for the GAN model.\n",
    "\n",
    "        Args:\n",
    "            real_images: Input batch of real images.\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary containing the updated loss metrics.\n",
    "        \"\"\"\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "        labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)\n",
    "\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        random_latent_vectors = tf.random.normal(\n",
    "            shape=(batch_size, self.latent_dim)\n",
    "        )\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(\n",
    "                self.generator(random_latent_vectors)\n",
    "            )\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(\n",
    "            zip(grads, self.generator.trainable_weights)\n",
    "        )\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_metric.result(),\n",
    "            \"g_loss\": self.g_loss_metric.result()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback for monitoring and saving generated images during training of a GAN model.\n",
    "\n",
    "    This callback generates and saves images at the end of each training epoch.\n",
    "\n",
    "    Args:\n",
    "        num_img (int, optional): Number of images to generate and save at the end of each epoch. Defaults to 3.\n",
    "        latent_dim (int, optional): Dimensionality of the latent space. Defaults to 128.\n",
    "\n",
    "    Attributes:\n",
    "        num_img (int): Number of images to generate and save at the end of each epoch.\n",
    "        latent_dim (int): Dimensionality of the latent space.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        \"\"\"\n",
    "        Initialize the GANMonitor callback.\n",
    "\n",
    "        Args:\n",
    "            num_img (int, optional): Number of images to generate and save at the end of each epoch. Defaults to 3.\n",
    "            latent_dim (int, optional): Dimensionality of the latent space. Defaults to 128.\n",
    "        \"\"\"\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\"\n",
    "        Callback function called at the end of each epoch.\n",
    "\n",
    "        Generates and saves images.\n",
    "\n",
    "        Args:\n",
    "            epoch (int): Current epoch number.\n",
    "            logs: Dictionary of logs containing the loss value.\n",
    "        \"\"\"\n",
    "        random_latent_vectors = tf.random.normal(\n",
    "            shape=(self.num_img, self.latent_dim)\n",
    "        )\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "\n",
    "        if not os.path.exists(\"generated_images\"):\n",
    "            os.makedirs(\"generated_images\")\n",
    "        for i in range(self.num_img):\n",
    "            img = keras.utils.array_to_img(generated_images[i])\n",
    "            img.save(os.path.join(\"generated_images\",f\"generated_img_{epoch:03d}_{i}.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GAN(discriminator=discriminator, generator=generator,latent_dim=latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.compile(\n",
    "    d_optimizer = keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    g_optimizer = keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss_fn = keras.losses.BinaryCrossentropy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154/154 [==============================] - 70s 393ms/step - d_loss: 0.4543 - g_loss: 1.4810\n",
      "Epoch 2/100\n",
      "154/154 [==============================] - 56s 366ms/step - d_loss: 0.5303 - g_loss: 1.4953\n",
      "Epoch 3/100\n",
      "154/154 [==============================] - 56s 366ms/step - d_loss: 0.5217 - g_loss: 1.4897\n",
      "Epoch 4/100\n",
      "154/154 [==============================] - 57s 367ms/step - d_loss: 0.6611 - g_loss: 1.4162\n",
      "Epoch 5/100\n",
      "154/154 [==============================] - 57s 367ms/step - d_loss: 0.4996 - g_loss: 1.5834\n",
      "Epoch 6/100\n",
      "154/154 [==============================] - 57s 368ms/step - d_loss: 0.6532 - g_loss: 1.8101\n",
      "Epoch 7/100\n",
      "154/154 [==============================] - 57s 368ms/step - d_loss: 0.5934 - g_loss: 0.9402\n",
      "Epoch 8/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.5457 - g_loss: 1.4947\n",
      "Epoch 9/100\n",
      "154/154 [==============================] - 57s 368ms/step - d_loss: 0.6348 - g_loss: 0.9869\n",
      "Epoch 10/100\n",
      "154/154 [==============================] - 56s 365ms/step - d_loss: 0.5973 - g_loss: 1.0272\n",
      "Epoch 11/100\n",
      "154/154 [==============================] - 56s 361ms/step - d_loss: 0.6063 - g_loss: 1.0427\n",
      "Epoch 12/100\n",
      "154/154 [==============================] - 56s 361ms/step - d_loss: 0.5715 - g_loss: 1.1303\n",
      "Epoch 13/100\n",
      "154/154 [==============================] - 56s 361ms/step - d_loss: 0.6290 - g_loss: 1.2779\n",
      "Epoch 14/100\n",
      "154/154 [==============================] - 56s 365ms/step - d_loss: 0.5962 - g_loss: 1.2046\n",
      "Epoch 15/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6692 - g_loss: 1.1353\n",
      "Epoch 16/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.5821 - g_loss: 1.1584\n",
      "Epoch 17/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.5773 - g_loss: 1.6812\n",
      "Epoch 18/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.5800 - g_loss: 2.2168\n",
      "Epoch 19/100\n",
      "154/154 [==============================] - 56s 361ms/step - d_loss: 0.5993 - g_loss: 1.3899\n",
      "Epoch 20/100\n",
      "154/154 [==============================] - 56s 364ms/step - d_loss: 0.6315 - g_loss: 0.9531\n",
      "Epoch 21/100\n",
      "154/154 [==============================] - 56s 364ms/step - d_loss: 0.6576 - g_loss: 0.8962\n",
      "Epoch 22/100\n",
      "154/154 [==============================] - 57s 371ms/step - d_loss: 0.5723 - g_loss: 1.2091\n",
      "Epoch 23/100\n",
      "154/154 [==============================] - 58s 377ms/step - d_loss: 0.6330 - g_loss: 1.0256\n",
      "Epoch 24/100\n",
      "154/154 [==============================] - 58s 374ms/step - d_loss: 0.6054 - g_loss: 1.2707\n",
      "Epoch 25/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6008 - g_loss: 1.1196\n",
      "Epoch 26/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6038 - g_loss: 1.0918\n",
      "Epoch 27/100\n",
      "154/154 [==============================] - 57s 368ms/step - d_loss: 0.6477 - g_loss: 1.0317\n",
      "Epoch 28/100\n",
      "154/154 [==============================] - 57s 372ms/step - d_loss: 0.6135 - g_loss: 1.3369\n",
      "Epoch 29/100\n",
      "154/154 [==============================] - 57s 370ms/step - d_loss: 0.6110 - g_loss: 1.2568\n",
      "Epoch 30/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.5458 - g_loss: 1.1984\n",
      "Epoch 31/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6370 - g_loss: 1.2217\n",
      "Epoch 32/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6640 - g_loss: 1.2552\n",
      "Epoch 33/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6162 - g_loss: 1.0190\n",
      "Epoch 34/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6863 - g_loss: 0.8632\n",
      "Epoch 35/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6563 - g_loss: 1.0284\n",
      "Epoch 36/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.7040 - g_loss: 0.8939\n",
      "Epoch 37/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6019 - g_loss: 1.2929\n",
      "Epoch 38/100\n",
      "154/154 [==============================] - 57s 368ms/step - d_loss: 0.6250 - g_loss: 1.1573\n",
      "Epoch 39/100\n",
      "154/154 [==============================] - 57s 367ms/step - d_loss: 0.6394 - g_loss: 0.8738\n",
      "Epoch 40/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6776 - g_loss: 0.9251\n",
      "Epoch 41/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6341 - g_loss: 1.0225\n",
      "Epoch 42/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6431 - g_loss: 0.9182\n",
      "Epoch 43/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6500 - g_loss: 1.1108\n",
      "Epoch 44/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6183 - g_loss: 0.9906\n",
      "Epoch 45/100\n",
      "154/154 [==============================] - 57s 367ms/step - d_loss: 0.6762 - g_loss: 1.4008\n",
      "Epoch 46/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6570 - g_loss: 1.2231\n",
      "Epoch 47/100\n",
      "154/154 [==============================] - 57s 368ms/step - d_loss: 0.6682 - g_loss: 0.9373\n",
      "Epoch 48/100\n",
      "154/154 [==============================] - 57s 368ms/step - d_loss: 0.6951 - g_loss: 1.0089\n",
      "Epoch 49/100\n",
      "154/154 [==============================] - 57s 368ms/step - d_loss: 0.6748 - g_loss: 0.7850\n",
      "Epoch 50/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6443 - g_loss: 0.9120\n",
      "Epoch 51/100\n",
      "154/154 [==============================] - 57s 368ms/step - d_loss: 0.6520 - g_loss: 0.9106\n",
      "Epoch 52/100\n",
      "154/154 [==============================] - 57s 368ms/step - d_loss: 0.6744 - g_loss: 0.9387\n",
      "Epoch 53/100\n",
      "154/154 [==============================] - 56s 366ms/step - d_loss: 0.6469 - g_loss: 1.0041\n",
      "Epoch 54/100\n",
      "154/154 [==============================] - 56s 363ms/step - d_loss: 0.8459 - g_loss: 1.7838\n",
      "Epoch 55/100\n",
      "154/154 [==============================] - 56s 364ms/step - d_loss: 0.6323 - g_loss: 0.9649\n",
      "Epoch 56/100\n",
      "154/154 [==============================] - 56s 364ms/step - d_loss: 0.6798 - g_loss: 1.0304\n",
      "Epoch 57/100\n",
      "154/154 [==============================] - 56s 364ms/step - d_loss: 0.6502 - g_loss: 1.0964\n",
      "Epoch 58/100\n",
      "154/154 [==============================] - 56s 364ms/step - d_loss: 0.6805 - g_loss: 0.9167\n",
      "Epoch 59/100\n",
      "154/154 [==============================] - 56s 364ms/step - d_loss: 0.6377 - g_loss: 0.9517\n",
      "Epoch 60/100\n",
      "154/154 [==============================] - 56s 364ms/step - d_loss: 0.5922 - g_loss: 1.1314\n",
      "Epoch 61/100\n",
      "154/154 [==============================] - 56s 365ms/step - d_loss: 0.6410 - g_loss: 1.0162\n",
      "Epoch 62/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6791 - g_loss: 0.9537\n",
      "Epoch 63/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6527 - g_loss: 0.9899\n",
      "Epoch 64/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6086 - g_loss: 1.1120\n",
      "Epoch 65/100\n",
      "154/154 [==============================] - 56s 366ms/step - d_loss: 0.6685 - g_loss: 0.8712\n",
      "Epoch 66/100\n",
      "154/154 [==============================] - 56s 364ms/step - d_loss: 0.6454 - g_loss: 0.9875\n",
      "Epoch 67/100\n",
      "154/154 [==============================] - 56s 363ms/step - d_loss: 0.6555 - g_loss: 1.1259\n",
      "Epoch 68/100\n",
      "154/154 [==============================] - 56s 363ms/step - d_loss: 0.6177 - g_loss: 1.1620\n",
      "Epoch 69/100\n",
      "154/154 [==============================] - 56s 364ms/step - d_loss: 0.6325 - g_loss: 1.0570\n",
      "Epoch 70/100\n",
      "154/154 [==============================] - 56s 363ms/step - d_loss: 0.6572 - g_loss: 0.9907\n",
      "Epoch 71/100\n",
      "154/154 [==============================] - 56s 363ms/step - d_loss: 0.6240 - g_loss: 0.9551\n",
      "Epoch 72/100\n",
      "154/154 [==============================] - 56s 364ms/step - d_loss: 0.6616 - g_loss: 0.8973\n",
      "Epoch 73/100\n",
      "154/154 [==============================] - 56s 364ms/step - d_loss: 0.6641 - g_loss: 1.0189\n",
      "Epoch 74/100\n",
      "154/154 [==============================] - 56s 363ms/step - d_loss: 0.6360 - g_loss: 1.0854\n",
      "Epoch 75/100\n",
      "154/154 [==============================] - 56s 360ms/step - d_loss: 0.6174 - g_loss: 1.0178\n",
      "Epoch 76/100\n",
      "154/154 [==============================] - 55s 355ms/step - d_loss: 0.6625 - g_loss: 1.0124\n",
      "Epoch 77/100\n",
      "154/154 [==============================] - 56s 362ms/step - d_loss: 0.6902 - g_loss: 0.9146\n",
      "Epoch 78/100\n",
      "154/154 [==============================] - 56s 364ms/step - d_loss: 0.5908 - g_loss: 1.1749\n",
      "Epoch 79/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6812 - g_loss: 0.8942\n",
      "Epoch 80/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6365 - g_loss: 1.0794\n",
      "Epoch 81/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6948 - g_loss: 1.1403\n",
      "Epoch 82/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6640 - g_loss: 0.9507\n",
      "Epoch 83/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6822 - g_loss: 0.9818\n",
      "Epoch 84/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6865 - g_loss: 1.2006\n",
      "Epoch 85/100\n",
      "154/154 [==============================] - 57s 370ms/step - d_loss: 0.6549 - g_loss: 1.0357\n",
      "Epoch 86/100\n",
      "154/154 [==============================] - 57s 371ms/step - d_loss: 0.6285 - g_loss: 1.1318\n",
      "Epoch 87/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.7084 - g_loss: 1.0563\n",
      "Epoch 88/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6546 - g_loss: 1.0249\n",
      "Epoch 89/100\n",
      "154/154 [==============================] - 57s 370ms/step - d_loss: 0.6500 - g_loss: 0.9424\n",
      "Epoch 90/100\n",
      "154/154 [==============================] - 57s 368ms/step - d_loss: 0.6188 - g_loss: 1.1340\n",
      "Epoch 91/100\n",
      "154/154 [==============================] - 57s 368ms/step - d_loss: 0.6398 - g_loss: 1.0066\n",
      "Epoch 92/100\n",
      "154/154 [==============================] - 57s 368ms/step - d_loss: 0.6913 - g_loss: 0.9844\n",
      "Epoch 93/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6568 - g_loss: 0.9300\n",
      "Epoch 94/100\n",
      "154/154 [==============================] - 57s 368ms/step - d_loss: 0.6210 - g_loss: 1.0186\n",
      "Epoch 95/100\n",
      "154/154 [==============================] - 57s 368ms/step - d_loss: 0.6698 - g_loss: 0.9426\n",
      "Epoch 96/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6367 - g_loss: 1.0312\n",
      "Epoch 97/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.6802 - g_loss: 0.9614\n",
      "Epoch 98/100\n",
      "154/154 [==============================] - 57s 370ms/step - d_loss: 0.6664 - g_loss: 0.9271\n",
      "Epoch 99/100\n",
      "154/154 [==============================] - 57s 369ms/step - d_loss: 0.7060 - g_loss: 0.9636\n",
      "Epoch 100/100\n",
      "154/154 [==============================] - 57s 370ms/step - d_loss: 0.6104 - g_loss: 1.1119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f9854193f0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan.fit(dataset,epochs=epochs,callbacks=[GANMonitor(num_img=10,latent_dim=latent_dim)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
